{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.contrib.slim as slim\n",
    "\n",
    "import data_provider\n",
    "import model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_DATA_ROOT = '/imagenet/train/' # ADJUST\n",
    "TRAIN_LIST_FILE = '/imagenet/train.txt' # ADJUST\n",
    "\n",
    "BATCH_SIZE = 64  # ADJUST\n",
    "CROP_SIZE = 224 # ADJUST\n",
    "CLASSES = [281, 239] # [Tabby cat; Bernese mountain dog]\n",
    "LR_START = 0.01 # ADJUST\n",
    "LR_END = LR_START / 1e4 # ADJUST\n",
    "MOMENTUM = 0.9 # ADJUST\n",
    "NUM_EPOCHS = 1000 # ADJUST\n",
    "OUTPUT_ROOT = 'data/checkpoints/vggA_BN' # ADJUST\n",
    "LOG_EVERY_N = 10 # ADJUST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare training data queue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/training/input.py:187: QueueRunner.__init__ (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/training/input.py:187: add_queue_runner (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "Number of train samples: 2600\n",
      "Number of train iterations: 40625\n"
     ]
    }
   ],
   "source": [
    "train_image, train_label, num_samples = data_provider.imagenet_data(\n",
    "    TRAIN_DATA_ROOT,\n",
    "    TRAIN_LIST_FILE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    crop_size=(CROP_SIZE, CROP_SIZE),\n",
    "    classes=CLASSES,\n",
    ")\n",
    "\n",
    "iters = NUM_EPOCHS * num_samples // BATCH_SIZE\n",
    "print('Number of train samples: {}'.format(num_samples))\n",
    "print('Number of train iterations: {}'.format(iters))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build network graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.variable_scope('net'):\n",
    "    logits = model.model(train_image, is_training=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope('loss'):\n",
    "    loss = tf.losses.sparse_softmax_cross_entropy(\n",
    "        labels=train_label, logits=logits)\n",
    "_=tf.summary.scalar('loss/loss', loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup training parameters and structures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_step = tf.train.get_or_create_global_step()\n",
    "\n",
    "lr = tf.train.polynomial_decay(LR_START, global_step, iters, LR_END)\n",
    "tf.summary.scalar('learning_rate', lr)\n",
    "\n",
    "optimizer = tf.train.MomentumOptimizer(learning_rate=lr, momentum=MOMENTUM)\n",
    "train_op = slim.learning.create_train_op(loss, \n",
    "    optimizer, global_step=global_step)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py:804: start_queue_runners (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "INFO:tensorflow:Saving checkpoints for 0 into data/checkpoints/vggA_BN/model.ckpt.\n",
      "[0 / 40625] loss_net = 0.7330480217933655\n",
      "..."
     ]
    }
   ],
   "source": [
    "with tf.train.MonitoredTrainingSession(checkpoint_dir=OUTPUT_ROOT) as sess:\n",
    "\n",
    "    start_iter = sess.run(global_step)\n",
    "    for it in range(start_iter, iters):\n",
    "\n",
    "        loss_value = sess.run(train_op)\n",
    "\n",
    "        if it % LOG_EVERY_N == 0:\n",
    "            print('[{} / {}] loss_net = {}'.format(it, iters, loss_value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
